# Release Notes

## Версия 1.0

**Дата релиза:** 14-02-2026

---

### Реализованный функционал

- Скачивание минимум 100 HTML-страниц
- Проверка типа содержимого (только text/html)
- Проверка единого языка страниц
- Сохранение страниц в формате .txt
- Сохранение HTML-разметки
- Удаление ссылок на:
  - JavaScript
  - CSS
  - Изображения
- Создание файла `index.txt` (номер страницы + URL)
- Создание архива `pages.zip`
- Обработка ошибок соединения и HTTP-статусов
- Добавление задержки между запросами для предотвращения блокировки

---

### Используемые библиотеки

- `requests` — HTTP-запросы  
- `BeautifulSoup` — анализ HTML  
- `langdetect` — определение языка  
- `zipfile` — создание архива  

---

### Ограничения

- Требуется подключение к интернету  
- Некоторые страницы могут быть пропущены при ошибке соединения  
- Определение языка может быть неточным для коротких страниц  
- Сервер может ограничивать частоту запросов  


## Версия 2.0

**Дата релиза:** 15-02-2026

---

### Реализованный функционал

#### Токенизация

- Извлечение чистого текста из HTML-документов
- Токенизация текста:
  - приведение к нижнему регистру  
  - удаление HTML-разметки  
  - удаление чисел  
  - удаление слов, содержащих одновременно буквы и цифры  
  - удаление стоп-слов  
  - удаление коротких слов (длина ≤ 2)  
  - удаление дубликатов
- Формирование файла `tokens.txt`
  - формат: один токен на строку

#### Лемматизация

- Реализована лемматизация на основе правил
- Обработка:
  - множественного числа существительных (`companies → company`)  
  - форм глаголов (`running → run`, `played → play`)  
  - сравнительной и превосходной степени (`bigger → big`)  
  - неправильных форм (`went → go`, `better → good`)
- Группировка токенов по леммам
- Формирование файла `lemmas.txt`
  - формат строки:  
    `<лемма> <токен1> <токен2> ... <токенN>`

---

### Используемые библиотеки

- `re` — токенизация  
- `collections` — группировка данных  

---

### Ограничения

- Лемматизация реализована на основе правил и не учитывает все языковые исключения  


## Версия 3.0

**Дата релиза:** 16-02-2026

---

### Реализованный функционал

#### Инвертированный индекс

- Построение инвертированного индекса по леммам:
  - ключ — лемма  
  - значение — множество идентификаторов документов, содержащих эту лемму
- Сохранение индекса в файл `inverted_index.txt`

#### Булев поиск

- Поддержка операторов:
  - `AND` — пересечение множеств  
  - `OR` — объединение множеств  
  - `NOT` — исключение множества из всех документов
- Поддержка сложных запросов с скобками, например:  
  `(Клеопатра AND Цезарь) OR (Антоний AND Цицерон) OR Помпей`
- Вывод URL найденных документов на основе `index.txt`

---

### Используемые библиотеки

- `re` — разбор запроса  
- `collections` — хранение индекса и группировка данных  

---

### Ограничения

- Булев поиск работает по леммам на основе правил, без учета контекста  
- Для корректного `NOT` требуется актуальный список всех документов  
- При больших объёмах текста обработка запроса может занимать заметное время  


---

## Версия 4.0

**Дата релиза:** 17-02-2026

---

### Реализованный функционал

#### Расчёт TF-IDF

* Для каждого скачанного документа выполнен расчёт:

  * **TF (Term Frequency)** — относительная частота термина в документе
  * **IDF (Inverse Document Frequency)** — логарифмическая мера редкости термина в коллекции
  * **TF-IDF** — произведение TF и IDF

* Расчёт производится:

  * для терминов из `tokens.txt`
  * для лемматизированных форм из `lemmas.txt`

* TF вычисляется как:

  ```
  TF = количество вхождений термина / общее число терминов в документе
  ```

* IDF вычисляется по формуле:

  ```
  IDF = log(N / df)
  ```

  где:

  * `N` — общее количество документов
  * `df` — число документов, содержащих термин

* Для каждого документа создаются файлы:

  * `tfidf_terms_<doc_id>.txt`
  * `tfidf_lemmas_<doc_id>.txt`

  Формат строки файла:

  ```
  <термин или лемма> <idf> <tf-idf>
  ```

* Результаты автоматически сохраняются в папку:

  ```
  tfidf_results/
  ├── terms/
  └── lemmas/
  ```

* Дополнительно формируются архивы:

  * `terms.zip`
  * `lemmas.zip`

---

### Используемые библиотеки

* `math` — вычисление логарифма
* `collections.Counter` — подсчёт частоты терминов
* `collections.defaultdict` — подсчёт document frequency
* `zipfile` — создание архивов

---

### Ограничения

* Используется базовая формула IDF без сглаживания
* Не применяется нормализация векторов документов
* При большом количестве документов возможен рост времени обработки

---
